{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b2d58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import torch\n",
    "import torchinfo\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "from utils import download_qwen3_small, Qwen3Tokenizer\n",
    "from qwen3 import Qwen3Model, QWEN_CONFIG_06_B, KVCache\n",
    "from typing import List, Tuple, Optional, Generator, cast, Literal\n",
    "from IPython.display import Latex, Math, display\n",
    "from sympy.parsing import sympy_parser as spp\n",
    "from sympy.core.sympify import SympifyError\n",
    "from tokenize import TokenError\n",
    "from sympy import Expr, simplify\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add85d7a",
   "metadata": {},
   "source": [
    "# 3.2 Loading a pre-trained model to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f334a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHICH_MODEL = \"base\"\n",
    "USE_COMPILE = False\n",
    "RE_NUMBER = re.compile(pattern=r\"-?(?:\\d+/\\d+|\\d+(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbbd55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "def set_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(device=\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(device=\"mps\")\n",
    "    else:\n",
    "        return torch.device(device=\"cpu\")\n",
    "\n",
    "\n",
    "device = set_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b280c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen3-0.6B-base.pth: 100% (1433 MiB / 1433 MiB)\n",
      "tokenizer-base.json: 100% (6 MiB / 6 MiB)\n"
     ]
    }
   ],
   "source": [
    "if WHICH_MODEL == \"base\":\n",
    "    download_qwen3_small(kind=\"base\", tokenizer_only=False, out_dir=\"qwen3\")\n",
    "    tokenizer_path = Path(\"qwen3\") / \"tokenizer-base.json\"\n",
    "    model_path = Path(\"qwen3\") / \"qwen3-0.6B-base.pth\"\n",
    "    tokenizer = Qwen3Tokenizer(tokenizer_file_path=tokenizer_path)\n",
    " \n",
    "elif WHICH_MODEL == \"reasoning\":\n",
    "    download_qwen3_small(kind=\"reasoning\", tokenizer_only=False, out_dir=\"qwen3\")\n",
    "    tokenizer_path = Path(\"qwen3\") / \"tokenizer-reasoning.json\"\n",
    "    model_path = Path(\"qwen3\") / \"qwen3-0.6B-reasoning.pth\"\n",
    "    tokenizer = Qwen3Tokenizer(\n",
    "        tokenizer_file_path=tokenizer_path,\n",
    "        apply_chat_template=True,\n",
    "        add_generation_prompt=True,\n",
    "        add_thinking=True,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Invalid choice: WHICH_MODEL={WHICH_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6671ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, how are you today?\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "input_ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n",
    "input_ids = input_ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced5e229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name))                       Input Shape          Output Shape         Param #              Trainable\n",
       "=============================================================================================================================\n",
       "Qwen3Model (Qwen3Model)                       [1, 7]               [1, 7, 151936]       --                   True\n",
       "├─Embedding (tok_emb)                         [1, 7]               [1, 7, 1024]         155,582,464          True\n",
       "├─ModuleList (trf_blocks)                     --                   --                   --                   True\n",
       "│    └─TransformerBlock (0)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (1)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (2)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (3)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (4)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (5)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (6)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (7)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (8)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (9)                   [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (10)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (11)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (12)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (13)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (14)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (15)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (16)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (17)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (18)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (19)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (20)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (21)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (22)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (23)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (24)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (25)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (26)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "│    └─TransformerBlock (27)                  [1, 7, 1024]         [1, 7, 1024]         --                   True\n",
       "│    │    └─RMSNorm (norm1)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─GroupedQueryAttention (att)       [1, 7, 1024]         [1, 7, 1024]         6,291,712            True\n",
       "│    │    └─RMSNorm (norm2)                   [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "│    │    └─FeedForward (ff)                  [1, 7, 1024]         [1, 7, 1024]         9,437,184            True\n",
       "├─RMSNorm (final_norm)                        [1, 7, 1024]         [1, 7, 1024]         1,024                True\n",
       "├─Linear (out_head)                           [1, 7, 1024]         [1, 7, 151936]       155,582,464          True\n",
       "=============================================================================================================================\n",
       "Total params: 751,632,384\n",
       "Trainable params: 751,632,384\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 751.57\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 17.96\n",
       "Params size (MB): 1503.40\n",
       "Estimated Total Size (MB): 1521.36\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Qwen3Model(cfg=QWEN_CONFIG_06_B)\n",
    "model.load_state_dict(torch.load(f=model_path))\n",
    "model.to(device)\n",
    "\n",
    "torchinfo.summary(\n",
    "    model=model,\n",
    "    input_data=input_ids,\n",
    "    verbose=0,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9cfd74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_COMPILE:\n",
    "  torch._dynamo.config.allow_unspec_int_on_nn_module = True\n",
    "  model = cast(Qwen3Model, torch.compile(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052137e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate_text_basic_stream_cache(\n",
    "    model: Qwen3Model,\n",
    "    token_ids: torch.Tensor,\n",
    "    max_new_tokens: int,\n",
    "    eos_token_id: Optional[int] = None\n",
    ") -> Generator[torch.Tensor, None, None]:\n",
    "    \n",
    "    model.eval()\n",
    "    cache = KVCache(n_layers=model.cfg[\"n_layers\"])\n",
    "    model.reset_kv_cache()\n",
    " \n",
    "    out = model(token_ids, cache=cache)[:, -1]\n",
    "    for _ in range(max_new_tokens):\n",
    "        next_token = torch.argmax(out, dim=-1, keepdim=True)\n",
    " \n",
    "        if (eos_token_id is not None\n",
    "                and torch.all(next_token == eos_token_id)):\n",
    "            break\n",
    " \n",
    "        yield next_token\n",
    "        # token_ids = torch.cat([token_ids, next_token], dim=1)\n",
    "        out = model(next_token, cache=cache)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89bd6a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt: str = (\n",
    "    r\"If $a+b=3$ and $ab=\\tfrac{13}{6}$, \"\n",
    "    r\"what is the value of $a^2+b^2$?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08cf412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_ids_tensor = torch.tensor(tokenizer.encode(prompt), device=device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25ee20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To find the value of \\( a^2 + b^2 \\) given that \\( a + b = 3 \\) and \\( ab = \\frac{13}{6} \\), we can use the following algebraic identity:\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = (a + b)^2 - 2ab\n",
      "\\]\n",
      "\n",
      "**Step 1:** Substitute the given values into the equation.\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = (3)^2 - 2 \\left( \\frac{13}{6} \\right)\n",
      "\\]\n",
      "\n",
      "**Step 2:** Calculate \\( (3)^2 \\).\n",
      "\n",
      "\\[\n",
      "(3)^2 = 9\n",
      "\\]\n",
      "\n",
      "**Step 3:** Calculate \\( 2 \\times \\frac{13}{6} \\).\n",
      "\n",
      "\\[\n",
      "2 \\times \\frac{13}{6} = \\frac{26}{6} = \\frac{13}{3}\n",
      "\\]\n",
      "\n",
      "**Step 4:** Subtract the second result from the first.\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = 9 - \\frac{13}{3}\n",
      "\\]\n",
      "\n",
      "**Step 5:** Convert 9 to a fraction with a denominator of 3 to perform the subtraction.\n",
      "\n",
      "\\[\n",
      "9 = \\frac{27}{3}\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = \\frac{27}{3} - \\frac{13}{3} = \\frac{14}{3}\n",
      "\\]\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "\\[\n",
      "\\boxed{\\dfrac{14}{3}}\n",
      "\\]"
     ]
    }
   ],
   "source": [
    "all_token_ids = []\n",
    " \n",
    "for token in generate_text_basic_stream_cache(\n",
    "    model=model,\n",
    "    token_ids=input_token_ids_tensor,\n",
    "    max_new_tokens=2048,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    "):\n",
    "    token_id = token.squeeze(0)\n",
    "    decoded_id = tokenizer.decode(token_id.tolist())\n",
    "    print(\n",
    "        decoded_id,   \n",
    "        end=\"\",\n",
    "        flush=True\n",
    "    )\n",
    "    all_token_ids.append(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "485daadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       " To find the value of \\( a^2 + b^2 \\) given that \\( a + b = 3 \\) and \\( ab = \\frac{13}{6} \\), we can use the following algebraic identity:\n",
       "\n",
       "\\[\n",
       "a^2 + b^2 = (a + b)^2 - 2ab\n",
       "\\]\n",
       "\n",
       "**Step 1:** Substitute the given values into the equation.\n",
       "\n",
       "\\[\n",
       "a^2 + b^2 = (3)^2 - 2 \\left( \\frac{13}{6} \\right)\n",
       "\\]\n",
       "\n",
       "**Step 2:** Calculate \\( (3)^2 \\).\n",
       "\n",
       "\\[\n",
       "(3)^2 = 9\n",
       "\\]\n",
       "\n",
       "**Step 3:** Calculate \\( 2 \\times \\frac{13}{6} \\).\n",
       "\n",
       "\\[\n",
       "2 \\times \\frac{13}{6} = \\frac{26}{6} = \\frac{13}{3}\n",
       "\\]\n",
       "\n",
       "**Step 4:** Subtract the second result from the first.\n",
       "\n",
       "\\[\n",
       "a^2 + b^2 = 9 - \\frac{13}{3}\n",
       "\\]\n",
       "\n",
       "**Step 5:** Convert 9 to a fraction with a denominator of 3 to perform the subtraction.\n",
       "\n",
       "\\[\n",
       "9 = \\frac{27}{3}\n",
       "\\]\n",
       "\n",
       "\\[\n",
       "a^2 + b^2 = \\frac{27}{3} - \\frac{13}{3} = \\frac{14}{3}\n",
       "\\]\n",
       "\n",
       "**Final Answer:**\n",
       "\n",
       "\\[\n",
       "\\boxed{\\dfrac{14}{3}}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_tokens = tokenizer.decode(all_token_ids)\n",
    "\n",
    "display(Latex(all_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da98b76",
   "metadata": {},
   "source": [
    "# 3.3 Implementing a wrapper for easier text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdbe1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_stream_concat(\n",
    "    model: Qwen3Model, tokenizer: Qwen3Tokenizer, prompt: str, \n",
    "    device: torch.device, max_new_tokens: int, verbose: bool=False) -> str:\n",
    "    \n",
    "    input_ids = torch.tensor(tokenizer.encode(prompt), device=device).unsqueeze(0)\n",
    " \n",
    "    generated_ids: List[int] = []\n",
    "    for token in generate_text_basic_stream_cache(\n",
    "        model=model,\n",
    "        token_ids=input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    ):\n",
    "        next_token_id_tensor = token.squeeze(0)\n",
    "        next_token_id = cast(typ=int, val=next_token_id_tensor.item())\n",
    "        generated_ids.append(next_token_id)\n",
    " \n",
    "        \n",
    "        if verbose:\n",
    "            print(\n",
    "                tokenizer.decode(token_ids=next_token_id_tensor.tolist()),\n",
    "                end=\"\",\n",
    "                flush=True\n",
    "            )\n",
    "    \n",
    "    return tokenizer.decode(token_ids=generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67e2b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To find the value of \\( a^2 + b^2 \\) given that \\( a + b = 3 \\) and \\( ab = \\frac{13}{6} \\), we can use the following algebraic identity:\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = (a + b)^2 - 2ab\n",
      "\\]\n",
      "\n",
      "**Step 1:** Substitute the given values into the equation.\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = (3)^2 - 2 \\left( \\frac{13}{6} \\right)\n",
      "\\]\n",
      "\n",
      "**Step 2:** Calculate \\( (3)^2 \\).\n",
      "\n",
      "\\[\n",
      "(3)^2 = 9\n",
      "\\]\n",
      "\n",
      "**Step 3:** Calculate \\( 2 \\times \\frac{13}{6} \\).\n",
      "\n",
      "\\[\n",
      "2 \\times \\frac{13}{6} = \\frac{26}{6} = \\frac{13}{3}\n",
      "\\]\n",
      "\n",
      "**Step 4:** Subtract the second result from the first.\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = 9 - \\frac{13}{3}\n",
      "\\]\n",
      "\n",
      "**Step 5:** Convert 9 to a fraction with a denominator of 3 to perform the subtraction.\n",
      "\n",
      "\\[\n",
      "9 = \\frac{27}{3}\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = \\frac{27}{3} - \\frac{13}{3} = \\frac{14}{3}\n",
      "\\]\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "\\[\n",
      "\\boxed{\\dfrac{14}{3}}\n",
      "\\]"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text_stream_concat(\n",
    "    model, tokenizer, prompt, device,\n",
    "    max_new_tokens=2048,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2c3f1",
   "metadata": {},
   "source": [
    "# 3.4 Extracting the final answer box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d85b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_answer = (\n",
    "r\"\"\"... some explanation...\n",
    "**Final Answer:**\n",
    " \n",
    "\\[\n",
    "\\boxed{\\dfrac{14}{3}}\n",
    "\\]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca38a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_boxed(text: str) -> Optional[str]:\n",
    "    boxed_start_idx = text.rfind(r\"\\boxed\")\n",
    "    if boxed_start_idx == -1:\n",
    "        return None\n",
    " \n",
    "    current_idx = boxed_start_idx + len(r\"\\boxed\")\n",
    " \n",
    "\n",
    "    while current_idx < len(text) and text[current_idx].isspace():\n",
    "        current_idx += 1\n",
    " \n",
    "\n",
    "    if current_idx >= len(text) or text[current_idx] != \"{\":\n",
    "        return None\n",
    " \n",
    "    current_idx += 1\n",
    "    brace_depth = 1\n",
    "    content_start_idx = current_idx\n",
    " \n",
    "\n",
    "    while current_idx < len(text) and brace_depth > 0:\n",
    "        char = text[current_idx]\n",
    "        if char == \"{\":\n",
    "            brace_depth += 1\n",
    "        elif char == \"}\":\n",
    "            brace_depth -= 1\n",
    "        current_idx += 1\n",
    " \n",
    "    \n",
    "    if brace_depth != 0:\n",
    "        return None\n",
    " \n",
    "    \n",
    "    return text[content_start_idx:current_idx-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1af1539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\dfrac{14}{3}\n"
     ]
    }
   ],
   "source": [
    "extracted_answer = get_last_boxed(model_answer)\n",
    "print(extracted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e09230bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\dfrac{14}{3}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Math(r\"\\dfrac{14}{3}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0576a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fallback = Literal[\n",
    "    \"number_then_full\", # (default): pick the last simple number, else the whole text\n",
    "    \"number_only\", # pick the last simple number, else return an empty string \"\";\n",
    "    \"none\" # extract only boxed content, else return empty string \"\".\n",
    "]\n",
    "\n",
    "def extract_final_candidate(text: str, fallback: Fallback=\"number_then_full\") -> str:\n",
    "    \n",
    "    result = \"\"\n",
    " \n",
    "    if text:\n",
    "        boxed = get_last_boxed(text.strip())\n",
    "        if boxed:\n",
    "            result = boxed.strip().strip(\"$ \")\n",
    "        elif fallback in (\"number_then_full\", \"number_only\"):\n",
    "            m = RE_NUMBER.findall(text)\n",
    "            if m:\n",
    "                result = m[-1]\n",
    "            elif fallback == \"number_then_full\":\n",
    "                result = text\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "049fa954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\dfrac{14}{3}\n",
      "14/3.\n",
      "14/3\n"
     ]
    }
   ],
   "source": [
    "print(extract_final_candidate(model_answer))\n",
    "print(extract_final_candidate(r\"\\boxed{ 14/3. }\"))\n",
    "print(extract_final_candidate(\"abc < > 14/3 abc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0f161",
   "metadata": {},
   "source": [
    "# 3.5 Normalizing the extracted answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19ae3af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATEX_FIXES = [\n",
    "    (r\"\\\\left\\s*\", \"\"),\n",
    "    (r\"\\\\right\\s*\", \"\"),\n",
    "    (r\"\\\\,|\\\\!|\\\\;|\\\\:\", \"\"),\n",
    "    (r\"\\\\cdot\", \"*\"),\n",
    "    (r\"\\u00B7|\\u00D7\", \"*\"),\n",
    "    (r\"\\\\\\^\\\\circ\", \"\"),\n",
    "    (r\"\\\\dfrac\", r\"\\\\frac\"),\n",
    "    (r\"\\\\tfrac\", r\"\\\\frac\"),\n",
    "    (r\"°\", \"\"),\n",
    "]\n",
    " \n",
    "RE_SPECIAL = re.compile(r\"<\\|[^>]+?\\|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69e7686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = RE_SPECIAL.sub(repl=\"\", string=text).strip()\n",
    " \n",
    "    text = re.sub(pattern=r\"\\^\\s*\\{\\s*\\\\circ\\s*\\}\", repl=\"\", string=text)\n",
    "    text = re.sub(pattern=r\"\\^\\s*\\\\circ\", repl=\"\", string=text)\n",
    "    text = text.replace(\"°\", \"\")\n",
    " \n",
    "    match = re.match(pattern=r\"^\\\\text\\{(?P<x>.+?)\\}$\", string=text)\n",
    "    if match:\n",
    "        text = match.group(\"x\")\n",
    " \n",
    "    text = re.sub(pattern=r\"\\\\\\(|\\\\\\)|\\\\\\[|\\\\\\]\", repl=\"\", string=text)\n",
    " \n",
    "    \n",
    "    for pat, rep in LATEX_FIXES:\n",
    "        text = re.sub(pat, rep, text)\n",
    " \n",
    "\n",
    "    text = text.replace(\"\\\\%\", \"%\").replace(\"$\", \"\").replace(\"%\", \"\")\n",
    "    text = re.sub(\n",
    "        pattern=r\"\\\\sqrt\\s*\\{([^}]*)\\}\",\n",
    "        repl=lambda match: f\"sqrt({match.group(1)})\",\n",
    "        string=text\n",
    "    )\n",
    "    text = re.sub(\n",
    "        pattern=r\"\\\\sqrt\\s+([^\\\\\\s{}]+)\",\n",
    "        repl=lambda match: f\"sqrt({match.group(1)})\",\n",
    "        string=text\n",
    "    )\n",
    " \n",
    "\n",
    "    text = re.sub(\n",
    "        r\"\\\\frac\\s*\\{([^{}]+)\\}\\s*\\{([^{}]+)\\}\",\n",
    "        lambda match: f\"({match.group(1)})/({match.group(2)})\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"\\\\frac\\s+([^\\s{}]+)\\s+([^\\s{}]+)\",\n",
    "        lambda match: f\"({match.group(1)})/({match.group(2)})\",\n",
    "        text,\n",
    "    )\n",
    " \n",
    "\n",
    "    text = text.replace(\"^\", \"**\")\n",
    "    text = re.sub(\n",
    "        r\"(?<=\\d)\\s+(\\d+/\\d+)\",\n",
    "        lambda match: \"+\" + match.group(1),\n",
    "        text,\n",
    "    )\n",
    " \n",
    "\n",
    "    text = re.sub(\n",
    "        r\"(?<=\\d),(?=\\d\\d\\d(\\D|$))\",\n",
    "        \"\",\n",
    "        text,\n",
    "    )\n",
    " \n",
    "    return text.replace(\"{\", \"\").replace(\"}\", \"\").strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e9d8636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14)/(3)\n",
      "(14)/(3)\n"
     ]
    }
   ],
   "source": [
    "print(normalize_text(extract_final_candidate(model_answer)))\n",
    "print(normalize_text(r\"\\text{\\[\\frac{14}{3}\\]}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fae33",
   "metadata": {},
   "source": [
    "# 3.6 Verifying mathematical equivalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3680f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sympy_parser(expr: str) -> Optional[Expr]:\n",
    "    try:\n",
    "        e = spp.parse_expr(\n",
    "            s=expr,\n",
    "            transformations=(*spp.standard_transformations, spp.implicit_multiplication_application),\n",
    "            evaluate=True,\n",
    "        )\n",
    "        return e if isinstance(e, Expr) else None\n",
    "    except (SympifyError, SyntaxError, TypeError, IndexError, TokenError):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65a133cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/3\n",
      "14/3\n"
     ]
    }
   ],
   "source": [
    "print(sympy_parser(expr=normalize_text(extract_final_candidate(text=model_answer))))\n",
    "print(sympy_parser(expr=\"28/6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd49c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_check(expr_gtruth: str, expr_pred: str) -> bool:\n",
    "    if expr_gtruth == expr_pred:\n",
    "        return True\n",
    "\n",
    "    gtruth, pred = sympy_parser(expr_gtruth), sympy_parser(expr_pred)\n",
    " \n",
    "    if gtruth is not None and pred is not None:\n",
    "        try:\n",
    "            return simplify(expr=gtruth - pred) == 0\n",
    "        except (SympifyError, TypeError):\n",
    "            pass\n",
    " \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ac5126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(equality_check(expr_gtruth=normalize_text(text=\"13/4.\"), expr_pred=normalize_text(text=r\"(13)/(4)\")))\n",
    "print(equality_check(expr_gtruth=normalize_text(text=\"0.5\"), expr_pred=normalize_text(text=r\"(1)/(2)\")))\n",
    "print(equality_check(expr_gtruth=normalize_text(text=\"14/3\"), expr_pred=normalize_text(text=\"15/3\")))\n",
    "print(equality_check(expr_gtruth=normalize_text(text=\"(14/3, 2/3)\"), expr_pred=normalize_text(text=\"(14/3, 4/6)\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57286f",
   "metadata": {},
   "source": [
    "# 3.7 Grading answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcc483b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_parts(text: str) -> List[str]:\n",
    "    result = [text]\n",
    " \n",
    "    if text:\n",
    "        if (\n",
    "            len(text) >= 2\n",
    "            and text[0] in \"([\" and text[-1] in \")]\"\n",
    "            and \",\" in text[1:-1]\n",
    "        ):\n",
    "            items = [p.strip() for p in text[1:-1].split(\",\")]\n",
    "            if all(items):\n",
    "                result = items\n",
    "    else:\n",
    "        result = []\n",
    " \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3adf14b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14/3', '2/3']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_into_parts(normalize_text(r\"(14/3, 2/3)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec26dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_answer(pred_text: str, gt_text: str) -> bool:\n",
    "    result = False\n",
    "    if pred_text is not None and gt_text is not None:\n",
    "        gt_parts = split_into_parts(normalize_text(gt_text))\n",
    "        pred_parts = split_into_parts(normalize_text(pred_text))\n",
    " \n",
    "        if (gt_parts and pred_parts and len(gt_parts) == len(pred_parts)):\n",
    "            result = all(equality_check(gt, pred) for gt, pred in zip(gt_parts, pred_parts))\n",
    " \n",
    "    return result\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96d3035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(grade_answer(pred_text=\"14/3\", gt_text=r\"\\frac{14}{3}\"))\n",
    "print(grade_answer(pred_text=r\"(14/3, 2/3)\", gt_text=\"(14/3, 4/6)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c8a039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests: List[Tuple[str, str, str, bool]] = [\n",
    "        (\"check_1\", \"3/4\", r\"\\frac{3}{4}\", True),\n",
    "        (\"check_2\", \"(3)/(4)\", r\"3/4\", True),\n",
    "        (\"check_3\", r\"\\frac{\\sqrt{8}}{2}\", \"sqrt(2)\", True),\n",
    "        (\"check_4\", r\"\\( \\frac{1}{2} + \\frac{1}{6} \\)\", \"2/3\", True),\n",
    "        (\"check_5\", \"(1, 2)\", r\"(1,2)\", True),\n",
    "        (\"check_6\", \"(2, 1)\", \"(1, 2)\", False),\n",
    "        (\"check_7\", \"(1, 2, 3)\", \"(1, 2)\", False),\n",
    "        (\"check_8\", \"0.5\", \"1/2\", True),\n",
    "        (\"check_9\", \"0.3333333333\", \"1/3\", False),\n",
    "        (\"check_10\", \"1,234/2\", \"617\", True),\n",
    "        (\"check_11\", r\"\\text{2/3}\", \"2/3\", True),\n",
    "        (\"check_12\", \"50%\", \"1/2\", False),\n",
    "        (\"check_13\", r\"2\\cdot 3/4\", \"3/2\", True),\n",
    "        (\"check_14\", r\"90^\\circ\", \"90\", True),\n",
    "        (\"check_15\", r\"\\left(\\frac{3}{4}\\right)\", \"3/4\", True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66b38d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_demos_table(tests: List[Tuple[str, str, str, bool]]) -> None:\n",
    "    header = (\"Test\", \"Expect\", \"Got\", \"Status\")\n",
    "    rows = []\n",
    "    for name, pred, gtruth, expect in tests:\n",
    "        got = grade_answer(pred, gtruth)\n",
    "        status = \"PASS\" if got == expect else \"FAIL\"\n",
    "        rows.append((name, str(expect), str(got), status))\n",
    " \n",
    "    data = [header] + rows\n",
    "    \n",
    "    col_widths = [\n",
    "        max(len(row[i]) for row in data)\n",
    "        for i in range(len(header))\n",
    "    ]\n",
    " \n",
    "    for row in data:\n",
    "        line = \" | \".join(\n",
    "            row[i].ljust(col_widths[i])\n",
    "            for i in range(len(header))\n",
    "        )\n",
    "        print(line)\n",
    " \n",
    "    passed = sum(r[3] == \"PASS\" for r in rows)\n",
    "    print(f\"\\nPassed {passed}/{len(rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d932be02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test     | Expect | Got   | Status\n",
      "check_1  | True   | True  | PASS  \n",
      "check_2  | True   | True  | PASS  \n",
      "check_3  | True   | True  | PASS  \n",
      "check_4  | True   | True  | PASS  \n",
      "check_5  | True   | True  | PASS  \n",
      "check_6  | False  | False | PASS  \n",
      "check_7  | False  | False | PASS  \n",
      "check_8  | True   | True  | PASS  \n",
      "check_9  | False  | False | PASS  \n",
      "check_10 | True   | True  | PASS  \n",
      "check_11 | True   | True  | PASS  \n",
      "check_12 | False  | False | PASS  \n",
      "check_13 | True   | True  | PASS  \n",
      "check_14 | True   | True  | PASS  \n",
      "check_15 | True   | True  | PASS  \n",
      "\n",
      "Passed 15/15\n"
     ]
    }
   ],
   "source": [
    "run_demos_table(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbcac3",
   "metadata": {},
   "source": [
    "Exercise 3.1: Adding more test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3431d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests2: List[Tuple[str, str, str, bool]] = [\n",
    "        (\"check_1\", \"3/4\", r\"\\frac{3}{4}\", True),\n",
    "        (\"check_2\", \"(3)/(5)\", r\"3/4\", False),\n",
    "        (\"check_3\", r\"\\sqrt{3}\", \"1.73\", False),\n",
    "        (\"check_4\", r\"\\frac{1}{0}\", \"1/0\", True),\n",
    "        (\"check_5\", r\"+inf\", \"oo\", True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "066ce182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test    | Expect | Got   | Status\n",
      "check_1 | True   | True  | PASS  \n",
      "check_2 | False  | False | PASS  \n",
      "check_3 | False  | False | PASS  \n",
      "check_4 | True   | False | FAIL  \n",
      "check_5 | True   | False | FAIL  \n",
      "\n",
      "Passed 3/5\n"
     ]
    }
   ],
   "source": [
    "run_demos_table(tests2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715a6c55",
   "metadata": {},
   "source": [
    "# 3.8 Loading the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fecd3ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 500\n"
     ]
    }
   ],
   "source": [
    "local_path = Path(\"math500_test.json\")\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/reasoning-from-scratch/\"\n",
    "    \"main/ch03/01_main-chapter-code/math500_test.json\"\n",
    ")\n",
    " \n",
    "if local_path.exists():\n",
    "    with local_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        math_data = json.load(f)\n",
    "else:\n",
    "    with urlopen(url) as f:\n",
    "        math_data = json.load(f)\n",
    " \n",
    "print(\"Number of entries:\", len(math_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f333503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': '\\\\left( 3, \\\\frac{\\\\pi}{2} \\\\right)',\n",
      " 'level': 2,\n",
      " 'problem': 'Convert the point $(0,3)$ in rectangular coordinates to polar '\n",
      "            'coordinates.  Enter your answer in the form $(r,\\\\theta),$ where '\n",
      "            '$r > 0$ and $0 \\\\le \\\\theta < 2 \\\\pi.$',\n",
      " 'solution': 'We have that $r = \\\\sqrt{0^2 + 3^2} = 3.$  Also, if we draw the '\n",
      "             'line connecting the origin and $(0,3),$ this line makes an angle '\n",
      "             'of $\\\\frac{\\\\pi}{2}$ with the positive $x$-axis.\\n'\n",
      "             '\\n'\n",
      "             '[asy]\\n'\n",
      "             'unitsize(0.8 cm);\\n'\n",
      "             '\\n'\n",
      "             'draw((-0.5,0)--(3.5,0));\\n'\n",
      "             'draw((0,-0.5)--(0,3.5));\\n'\n",
      "             'draw(arc((0,0),3,0,90),red,Arrow(6));\\n'\n",
      "             '\\n'\n",
      "             'dot((0,3), red);\\n'\n",
      "             'label(\"$(0,3)$\", (0,3), W);\\n'\n",
      "             'dot((3,0), red);\\n'\n",
      "             '[/asy]\\n'\n",
      "             '\\n'\n",
      "             'Therefore, the polar coordinates are $\\\\boxed{\\\\left( 3, '\n",
      "             '\\\\frac{\\\\pi}{2} \\\\right)}.$',\n",
      " 'subject': 'Precalculus',\n",
      " 'unique_id': 'test/precalculus/807.json'}\n"
     ]
    }
   ],
   "source": [
    "pprint(math_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f48bf",
   "metadata": {},
   "source": [
    "# 3.9 Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f66bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
